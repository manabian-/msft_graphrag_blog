{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "292b5074-f242-4d07-bd60-9438f9e9d94d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Using SPARQL and the Knowledge Graph for RAG\n",
    "Now that the Knowledge Graph has been created we will use it to do local and global search.\n",
    "\n",
    "![](../images/RAG_with_KnowledgeGraph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad8b0abb-21bf-4ad1-99c3-dc4347378b2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## <add> install libraries and get config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2a260f2-ed48-4c28-8e45-01dd213dd7c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-vectorsearch databricks-langchain==0.8.1 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12f94863-4ea7-43fe-afe9-537a4f415ebe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install SPARQLWrapper openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27f24d88-6593-4666-b2b5-d59d394411ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U \"langchain-openai>=0.2.0\" \"langchain-core>=0.2.0\" \"langchain>=0.2.0\" \"openai>=1.42.0\" tiktoken -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2582f735-7b23-46df-869b-2884833f3bef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e589cdd-0118-4f45-ad5f-c9865b55e60f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "add"
    }
   },
   "outputs": [],
   "source": [
    "%run ./00_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73beaca5-a5cc-46dd-82c7-fd3c2e61281f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import urllib.parse\n",
    "import ast\n",
    "from io import StringIO\n",
    "from SPARQLWrapper import SPARQLWrapper, CSV, SELECT, POST, POSTDIRECTLY\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Dict, Any, List\n",
    "from openai import OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# from elasticsearch import Elasticsearch  # <delete>Commented out because Elasticsearch is not used\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7813e3e6-5e87-47ab-97be-2d557cf0a4ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Adjust pandas display settings\n",
    "pd.set_option(\n",
    "    \"display.max_colwidth\", None\n",
    ")  # Set to None to display the full column width\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8b967ff-ec0b-403d-8860-74483a8c6dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# <modify>Change to retrieve from `00_config`\n",
    "# endpoint for GraphDB\n",
    "# endpoint = \"http://localhost:7200/repositories/msft-graphrag-300\"\n",
    "\n",
    "endpoint = f\"{host}/repositories/{repository}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5794b81b-2e47-418e-9d57-fa3fac3aad23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "es_username = 'elastic'\n",
    "es_password = ''  # put your password here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11379131-a46e-4747-ac1f-afc675188da3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def sparql_query(query: str, post=False) -> pd.DataFrame:\n",
    "    sparql_conn.setQuery(query)\n",
    "    sparql_conn.setReturnFormat(CSV)\n",
    "    results = sparql_conn.query().convert()\n",
    "    return pd.read_csv(StringIO(results.decode('utf-8')), sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34ff3657-6dfb-4110-bd37-47def27a7a53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sparql_conn = SPARQLWrapper(endpoint)\n",
    "\n",
    "# <add> Set credentials for GraphDB \n",
    "sparql_conn.setCredentials(username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "887cbbef-6922-4ad3-8005-b0a3c44067a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup the question\n",
    "The question we will ask will be:\n",
    "```\n",
    "What is the relationship between Bob Cratchit and Belinda Cratchit?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44005f05-45cd-4a4e-91b2-1c699996a963",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "question_text = \"What is the relationship between Bob Cratchit and Belinda Cratchit?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3de8155-eb27-4185-ad7f-4bc43226dbd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Convert the question text\n",
    "First step is to convert the question into an embedding vector. To do this we will use our local LM Studio instance and call the embedding OpenAI endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7525273e-1ea9-49e9-8194-e80b91bda337",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# <modify> Change to Databricks Mosaic AI Model Serving processing\n",
    "# def get_embedding(text: str, client: Any, model: str=\"CompendiumLabs/bge-large-en-v1.5-gguf\"):\n",
    "#     \"\"\"Convert the text into an embedding vector using the model provided\n",
    "\n",
    "#     :param text: text to be converted to and embedding vector\n",
    "#     :param client: OpenAI client\n",
    "#     :param model: name of the model to use for encoding\n",
    "#     \"\"\"\n",
    "#     text = text.replace(\"\\n\", \" \")\n",
    "#     return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "def get_clinet():\n",
    "    token = (\n",
    "        dbutils.notebook.entry_point.getDbutils()\n",
    "        .notebook()\n",
    "        .getContext()\n",
    "        .apiToken()\n",
    "        .get()\n",
    "    )\n",
    "\n",
    "    # Databricks Workspace の URL をセット\n",
    "    ws_url = \"https://\"\n",
    "    ws_url += spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
    "\n",
    "    return OpenAI(\n",
    "        api_key=token,\n",
    "        base_url=f\"{ws_url}/serving-endpoints\",\n",
    "    )\n",
    "\n",
    "def get_embedding(text, client, model=\"databricks-bge-large-en\"):\n",
    "    embeddings = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    return embeddings.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9aaed081-9af1-4360-b1ce-78d575d1ea6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# <modify> Change to Databricks Mosaic AI Model Serving processing\n",
    "# client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "client = get_clinet()\n",
    "embedding_vector = get_embedding(question_text, client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cabb3669-a601-4c8d-ab0e-33b3c5aec327",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Set the limits for our searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f51187e-7de3-476f-8187-755d5c582407",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_chunks = 3\n",
    "top_communities = 3\n",
    "top_outside_relationships = 10\n",
    "top_inside_relationships = 10\n",
    "top_entities = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3be814b-76d2-4b11-8302-1b4d66726e27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Find nearest Entities\n",
    "Now we need to use our Elasticsearch index to do a k-nearest neighbour search for our **embedding_vector** to find the 10 nearest `Entity` instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c288db7-fd46-4d33-bf75-1556ed1925d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# <delete> Change to Mosaic AI Vector Search\n",
    "# es = Elasticsearch(\"http://localhost:9200\", \n",
    "#                    basic_auth=(es_username, es_password), \n",
    "#                    verify_certs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61aedb36-6288-4cec-b5a7-e0df3aeec862",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# <modify> Change to Mosaic AI Vector Search\n",
    "# query = {\n",
    "#     \"field\" : \"description_embedding\" ,\n",
    "#     \"query_vector\" : embedding_vector,\n",
    "#     \"k\" : top_entities,\n",
    "#     \"num_candidates\" : 100 ,\n",
    "# }\n",
    "# index_name = \"entity_graph_index\"\n",
    "# res = es.search(index=index_name, knn=query, source=[\"id\"])\n",
    "# search_results = res[\"hits\"][\"hits\"]\n",
    "# # convert our results into a list of Entities\n",
    "# # This list will be ordered by match score descending (i.e the more likely matches will be at the beginning)\n",
    "# entity_list = [x['_id'] for x in search_results]\n",
    "# entity_list\n",
    "\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "\n",
    "index_fqn = f\"{CATALOG}.{SCHEMA}.{INDEX_NAME}\"\n",
    "\n",
    "vsc = VectorSearchClient()\n",
    "index = vsc.get_index(index_name=index_fqn)\n",
    "res = index.similarity_search(\n",
    "    query_vector=embedding_vector,\n",
    "    columns=[\"id\"],\n",
    "    num_results=int(top_entities),\n",
    ")\n",
    "rows = res.get(\"result\", {}).get(\"data_array\", [])\n",
    "entity_list = [row[0] for row in rows]\n",
    "entity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1291853c-0569-498d-86d9-a37b19195715",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_entities(nodes: List[str]) -> str:\n",
    "    \"\"\"Get a SPARQL query that will fetch details of the Entites that are in the list\n",
    "    \n",
    "    :param nodes: list of Entity ids\n",
    "    :returns: a SPARQL query string\n",
    "    \"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    PREFIX gr: <http://ormynet.com/ns/msft-graphrag#>\n",
    "    \n",
    "    SELECT ?id ?description\n",
    "    WHERE\n",
    "    {\n",
    "        ?entity_uri a gr:Entity;\n",
    "        gr:id ?id;\n",
    "        gr:description ?entity_desc .\n",
    "        BIND(REPLACE(?entity_desc, \"\\\\r\\\\n\", \" \", \"i\") AS ?description)\n",
    "    \"\"\"\n",
    "    first = True\n",
    "    for node in nodes:\n",
    "        if first:\n",
    "            query += \" FILTER( \"\n",
    "        else:\n",
    "            query += \" || \"\n",
    "        query += f' ?id = \"{node}\" '\n",
    "        first = False\n",
    "    query += \"\"\" )\n",
    "    }\n",
    "    \"\"\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ad44286-c407-4aea-b10e-fc1e846aae1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get details about the Entities that were found\n",
    "entities_df =sparql_query(get_entities(entity_list))\n",
    "entities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5af33da-a97e-4d48-98b7-ce5530cf0cb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def convert_df_to_text(df: pd.DataFrame, key_name: str, colname: str):\n",
    "    \"\"\"Convert a DataFrame to text suitable for LLM context\n",
    "    \n",
    "    :param df: input DataFrame\n",
    "    :param key_name: name of the key to use\n",
    "    :param colname: name of the column in the DataFrame to use\n",
    "    :returns: string suitable for LLM context\n",
    "    \"\"\"\n",
    "    output_text = \"{\\\"\" + key_name + \":\\\" [\\n\"\n",
    "    first = True\n",
    "    for i in range(len(df)):\n",
    "        if first:\n",
    "            output_text += \"\\\"\"\n",
    "            first = False\n",
    "        else:\n",
    "            output_text += \",\\n\\\"\" \n",
    "        output_text += df[colname].iloc[i] + \"\\\"\"\n",
    "    output_text += \"]}\"\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71b723e1-0c15-4004-b841-cdffd5bf8031",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "entity_text = convert_df_to_text(entities_df, 'Entities', 'description')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12a4d44f-257d-451d-a7f5-e86a9c1e19eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Get The Top 3 Chunks\n",
    "Get the `Chunk` records that are connected to these `Entity` records, sort them by those that have the most Entities and then take the top 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "741d0cc0-d02e-4aab-afea-34c131395bdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_text_mapping(nodes: List[str], limit_chunks: int = 3) -> str:\n",
    "    \"\"\"Get a SPARQL query that fetches the top Chunks that are connected to Entity records\n",
    "    \n",
    "    :param nodes: list of Entity ids\n",
    "    :param limit_chunks: how many chunks to return\n",
    "    :returns: a SPARQL query string\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    PREFIX gr: <http://ormynet.com/ns/msft-graphrag#>\n",
    "    \n",
    "    SELECT \n",
    "    ?chunkText \n",
    "    (COUNT(?entity_uri) AS ?freq)\n",
    "    WHERE {\n",
    "        ?chunk_uri gr:has_entity ?entity_uri;\n",
    "        gr:text ?chunk_text .\n",
    "    \"\"\"\n",
    "    first = True\n",
    "    for node in nodes:\n",
    "        if not first:\n",
    "            query += \" UNION \"\n",
    "        query += f\"\"\"\n",
    "        {{\n",
    "            ?entity_uri a gr:Entity;\n",
    "            gr:id \"{node}\" .\n",
    "        }} \n",
    "        \"\"\"\n",
    "        first = False\n",
    "    query += \"\"\"\n",
    "        BIND(REPLACE(?chunk_text, \"\\\\r\\\\n\", \" \") as ?chunkText)\n",
    "    }\n",
    "    GROUP BY ?chunk_uri ?chunkText\n",
    "    ORDER BY DESC(?freq)\n",
    "    \"\"\"\n",
    "    query += f\" LIMIT {limit_chunks} \"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61e6ad5c-e9e4-422d-ae8e-eb0986c429e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's find the Chunks that are most likely to contain the information we're looking for\n",
    "text_mapping_df = sparql_query(get_text_mapping(entity_list, limit_chunks=top_chunks))\n",
    "text_mapping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbfb9071-f72e-4e12-9ef5-33a7cbd195c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chunk_text = convert_df_to_text(text_mapping_df, 'Chunks', 'chunkText')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa5fe45a-5ffd-4858-9ee6-a045316c3f19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Get the Top 3 Relationships\n",
    "Get the top 3 `Community` records that are related to these `Entity` records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f784e6f-2914-46e0-b169-264cae66dfba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# <modify> Changed to handle missing weight values so that data can be retrieved (code generated by AI, so there may be behavioral differences)\n",
    "# def get_report_mapping(nodes: List[str], limit_communities: int = 3) -> str:\n",
    "#     \"\"\"Get the Communities that are most likely to contain the Entities\n",
    "    \n",
    "#     :param nodes: list of Entity ids\n",
    "#     :param limit_communities: how many communities\n",
    "#     :returns: a SPARQL query string\n",
    "#     \"\"\"\n",
    "#     query = \"\"\"\n",
    "#     PREFIX gr: <http://ormynet.com/ns/msft-graphrag#>\n",
    "\n",
    "#     SELECT ?community_uri ?rank ?weight ?summary\n",
    "#     WHERE\n",
    "#     {\n",
    "#         ?community_uri a gr:Community;\n",
    "#           gr:rank ?rank;\n",
    "#           gr:weight ?weight;\n",
    "#           gr:summary ?community_summary .\n",
    "#         BIND(REPLACE(?community_summary, \"\\\\r\\\\n\", \" \", \"i\") AS ?summary)\n",
    "#         ?entity_uri gr:in_community ?community_uri;\n",
    "#     \"\"\"\n",
    "#     first = True\n",
    "#     for node in nodes:\n",
    "#         if not first:\n",
    "#             query += \" UNION \"\n",
    "#         query += f\"\"\"\n",
    "#         {{\n",
    "#             ?entity_uri a gr:Entity;\n",
    "#             gr:id \"{node}\" .\n",
    "#         }} \n",
    "#         \"\"\"\n",
    "#         first = False\n",
    "#     query += \"\"\"\n",
    "#     }\n",
    "#     GROUP BY ?rank ?weight ?community_uri ?summary\n",
    "#     ORDER BY DESC(?rank) DESC(?weight)\n",
    "#     \"\"\"\n",
    "#     query += f\" LIMIT {limit_communities} \"\n",
    "#     return query\n",
    "\n",
    "def get_report_mapping(nodes, limit_communities = 3) -> str:\n",
    "    \"\"\"\n",
    "    Generate a SPARQL query that returns communities containing the specified Entity IDs,\n",
    "    prioritizing those that contain more of the given entities.\n",
    "    In case of ties, results are ordered by rank and then by weight in descending order.\n",
    "    \"\"\"\n",
    "    if not nodes:\n",
    "        raise ValueError(\"At least one node is required.\")\n",
    "\n",
    "    # Remove duplicates while preserving order\n",
    "    seen, ids = set(), []\n",
    "    for n in map(str, nodes):\n",
    "        if n not in seen:\n",
    "            seen.add(n)\n",
    "            ids.append(n)\n",
    "\n",
    "    total = len(ids)\n",
    "\n",
    "    def esc(s: str) -> str:\n",
    "        # Simple escape for SPARQL literals\n",
    "        return s.replace(\"\\\\\", \"\\\\\\\\\").replace('\"', '\\\\\"')\n",
    "\n",
    "    values_block = \"\\n    \".join(f'\"{esc(i)}\"' for i in ids)\n",
    "\n",
    "    query = f\"\"\"\n",
    "    PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "    PREFIX gr:  <http://ormynet.com/ns/msft-graphrag#>\n",
    "\n",
    "    SELECT ?community_uri\n",
    "        (xsd:decimal(COALESCE(MAX(?rank0), MAX(?level0))) AS ?rank)\n",
    "        (MAX(?weightN) AS ?weight)\n",
    "        (REPLACE(STR(SAMPLE(?community_summary)), \"[\\\\\\\\r\\\\\\\\n]+\", \" \") AS ?summary)\n",
    "        (COUNT(DISTINCT ?id) AS ?match_count)\n",
    "        ((xsd:decimal(COUNT(DISTINCT ?id)) / xsd:decimal({total})) AS ?coverage)\n",
    "    WHERE {{\n",
    "    VALUES ?id {{\n",
    "        {values_block}\n",
    "    }}\n",
    "\n",
    "    ?entity_uri a gr:Entity ;\n",
    "                gr:id ?id ;\n",
    "                gr:in_community ?community_uri .\n",
    "\n",
    "    ?community_uri a gr:Community .\n",
    "\n",
    "    OPTIONAL {{ ?community_uri gr:rank  ?rank0 }}\n",
    "    OPTIONAL {{ ?community_uri gr:level ?level0 }}\n",
    "\n",
    "    OPTIONAL {{\n",
    "        ?community_uri gr:weight ?weight0 .\n",
    "        BIND(xsd:decimal(?weight0) AS ?weightN)\n",
    "    }}\n",
    "\n",
    "    OPTIONAL {{ ?community_uri gr:summary ?community_summary }}\n",
    "    }}\n",
    "    GROUP BY ?community_uri\n",
    "    ORDER BY DESC(?match_count) DESC(?rank) DESC(?weight)\n",
    "    LIMIT {limit_communities}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37124e56-b86c-4ffb-983c-422c6960727f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the top communities that these Entities are part of\n",
    "report_mapping_df = sparql_query(get_report_mapping(entity_list, limit_communities=top_communities))\n",
    "report_mapping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99cd1824-bdf7-4bb8-baae-8dcfbd9beb4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "reports_text = convert_df_to_text(report_mapping_df, 'Reports', 'summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fdb60cd-5f98-4f45-829d-45d5ff6c0edb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Get The Outside & Inside Relationships\n",
    "Get the outside and inside relationsihps for the `Entity` records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cee1391-1a44-4faa-aae8-e1039515f09b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_outside_relationships(nodes: List[str], limit_outside_relationships: int = 10) -> str:\n",
    "    \"\"\"Get the outside relationships\n",
    "    \n",
    "    :param nodes: list of Entity ids\n",
    "    :param limit_outside_relationships: how many relationships to return\n",
    "    :returns: a SPARQL query string\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    PREFIX gr: <http://ormynet.com/ns/msft-graphrag#>\n",
    "    \n",
    "    SELECT \n",
    "    ?description\n",
    "    ?entity_from_id ?entity_to_id\n",
    "    ?rank ?weight\n",
    "    WHERE {\n",
    "        ?related_to_uri a gr:related_to;\n",
    "            gr:id ?id;\n",
    "            gr:rank ?rank;\n",
    "            gr:description ?desc;\n",
    "            gr:weight ?weight .\n",
    "        BIND(REPLACE(?desc, \"\\\\r\\\\n\", \"\") as ?description)\n",
    "        ?entity_from_uri ?related_to_uri ?entity_to_uri .\n",
    "        ?entity_from_uri gr:id ?entity_from_id .\n",
    "        ?entity_to_uri gr:id ?entity_to_id .\n",
    "    \"\"\"\n",
    "    first = True\n",
    "    for node in nodes:\n",
    "        if first:\n",
    "            query += \" FILTER( \"\n",
    "        else:\n",
    "            query += \" && \"\n",
    "        query += f\"\"\"\n",
    "    ?entity_to_id != \"{node}\" \"\"\"\n",
    "        first = False\n",
    "    query += \"\"\"\n",
    "               )\n",
    "    }\n",
    "    ORDER BY DESC(?rank) DESC(?weight)\n",
    "    \"\"\"\n",
    "    query += f\" LIMIT {limit_outside_relationships} \"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "770da8c3-2d12-4c7c-b578-c2e6b1e23caa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the top outside relationships these Entities are not part of\n",
    "outside_relationships_df = sparql_query(get_outside_relationships(entity_list, limit_outside_relationships=top_outside_relationships))\n",
    "outside_relationships_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b79c8ef1-b02d-49df-b451-554eb2072abb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_inside_relationships(nodes: List[str], limit_inside_relationships: int = 10) -> str:\n",
    "    \"\"\"Get a SPARQL query to fetch the inside relationships\n",
    "    \n",
    "    :param nodes: list of Entity ids\n",
    "    :param limit_inside_relationships: how many relationships to return\n",
    "    :returns: a SPARQL query string\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    PREFIX gr: <http://ormynet.com/ns/msft-graphrag#>\n",
    "    SELECT \n",
    "    ?description\n",
    "    ?entity_from_id ?entity_to_id\n",
    "    ?rank ?weight\n",
    "    WHERE {\n",
    "        ?related_to_uri a gr:related_to;\n",
    "            gr:id ?id;\n",
    "            gr:rank ?rank;\n",
    "            gr:description ?desc;\n",
    "            gr:weight ?weight .\n",
    "        BIND(REPLACE(?desc, \"\\\\r\\\\n\", \"\") as ?description)\n",
    "        ?entity_from_uri ?related_to_uri ?entity_to_uri .\n",
    "        ?entity_from_uri gr:id ?entity_from_id .\n",
    "        ?entity_to_uri gr:id ?entity_to_id .\n",
    "    \"\"\"\n",
    "    first = True\n",
    "    for node in nodes:\n",
    "        if first:\n",
    "            query += \" FILTER( \"\n",
    "        else:\n",
    "            query += \" || \"\n",
    "        query += f\"\"\"\n",
    "        ?entity_to_id = \"{node}\" \"\"\"\n",
    "        first = False\n",
    "    query += \"\"\"\n",
    "               )\n",
    "    }\n",
    "    ORDER BY DESC(?rank) DESC(?weight)\n",
    "    \"\"\"\n",
    "    query += f\" LIMIT {limit_inside_relationships} \"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3925db30-5d6d-47bf-8f6e-b7e19b644b8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the top inside relationships these Entities are part of\n",
    "inside_relationships_df = sparql_query(get_inside_relationships(entity_list, limit_inside_relationships=top_inside_relationships))\n",
    "inside_relationships_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92f31404-0445-4dda-98f5-a49eadd90d05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "relationships_text = \"{\\\"Relationships:\\\" [ \"\n",
    "first = True\n",
    "for i in range(len(inside_relationships_df)):\n",
    "    if first:\n",
    "        relationships_text += \"\\\"\"\n",
    "        first = False\n",
    "    else:\n",
    "        relationships_text += \",\\n\\\"\" \n",
    "    relationships_text += inside_relationships_df['description'].iloc[i] + \"\\\"\"\n",
    "for i in range(len(outside_relationships_df)):\n",
    "    relationships_text += outside_relationships_df['description'].iloc[i] + \"\\\"\"\n",
    "relationships_text += \"]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5809750-55fe-42c7-9d4d-fb301564e5f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create LangChain Response\n",
    "Having got all our important data for our identified entity list, we now need to combine them to produce a response that would be suitable as a LangChain response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50821aa8-2005-4084-be17-90000704671e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# <modify>  Change to Databricks Mosaic AI Model Serving processing\n",
    "# llm = ChatOpenAI(\n",
    "#     model=\"lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF\",\n",
    "#     temperature=0,\n",
    "#     max_tokens=None,\n",
    "#     timeout=None,\n",
    "#     max_retries=2,\n",
    "#     api_key=\"lm-server\",\n",
    "#     base_url=\"http://localhost:1234/v1\"\n",
    "# )\n",
    "\n",
    "from databricks_langchain.chat_models import ChatDatabricks\n",
    "\n",
    "llm = ChatDatabricks(\n",
    "    endpoint=\"databricks-meta-llama-3-1-8b-instruct\",\n",
    "    temperature=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56a095d3-d883-44da-a215-f9e89bcfbfe7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Prompt with no context\n",
    "Prompt with no context fromt the Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bd83411-5e70-436c-b6b7-5a5061b4e8e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that answers questions about a book.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input\": question_text,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41438495-b317-498c-bc3e-bfc3691d537c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Prompt with context from Knowledge Graph\n",
    "Create a context using the Knowledge Graph and feed that to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98fdec9e-9835-4fea-b097-cda9952d95eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that answers questions about a book.\",\n",
    "        ),\n",
    "        (\"human\", \"{context} {input}\"),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"context\": entity_text + \",\" + chunk_text + \",\" + relationships_text +\",\" + reports_text,\n",
    "        \"input\": question_text,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0c2fa1b-d642-48fb-aacf-79a863fda249",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Global Query\n",
    "We'll setup a global query with 2 different prompt templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3dc7619-06f5-4087-b3af-16840d6ddaa4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MAP_SYSTEM_PROMPT = \"\"\"\n",
    "---Role---\n",
    "\n",
    "You are a helpful assistant responding to questions about data in the tables provided.\n",
    "\n",
    "\n",
    "---Goal---\n",
    "\n",
    "Generate a response consisting of a list of key points that responds to the user's question, summarizing all relevant information in the input data tables.\n",
    "\n",
    "You should use the data provided in the data tables below as the primary context for generating the response.\n",
    "If you don't know the answer or if the input data tables do not contain sufficient information to provide an answer, just say so. Do not make anything up.\n",
    "\n",
    "Each key point in the response should have the following element:\n",
    "- Description: A comprehensive description of the point.\n",
    "- Importance Score: An integer score between 0-100 that indicates how important the point is in answering the user's question. An 'I don't know' type of response should have a score of 0.\n",
    "\n",
    "The response should be JSON formatted as follows:\n",
    "{{\n",
    "    \"points\": [\n",
    "        {{\"description\": \"Description of point 1 [Data: Reports (report ids)]\", \"score\": score_value}},\n",
    "        {{\"description\": \"Description of point 2 [Data: Reports (report ids)]\", \"score\": score_value}}\n",
    "    ]\n",
    "}}\n",
    "\n",
    "The response shall preserve the original meaning and use of modal verbs such as \"shall\", \"may\" or \"will\".\n",
    "\n",
    "Points supported by data should list the relevant reports as references as follows:\n",
    "\"This is an example sentence supported by data references [Data: Reports (report ids)]\"\n",
    "\n",
    "**Do not list more than 5 record ids in a single reference**. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
    "\n",
    "For example:\n",
    "\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (2, 7, 64, 46, 34, +more)]. He is also CEO of company X [Data: Reports (1, 3)]\"\n",
    "\n",
    "where 1, 2, 3, 7, 34, 46, and 64 represent the id (not the index) of the relevant data report in the provided tables.\n",
    "\n",
    "Do not include information where the supporting evidence for it is not provided.\n",
    "\n",
    "\n",
    "---Data tables---\n",
    "\n",
    "{context_data}\n",
    "\n",
    "---Goal---\n",
    "\n",
    "Generate a response consisting of a list of key points that responds to the user's question, summarizing all relevant information in the input data tables.\n",
    "\n",
    "You should use the data provided in the data tables below as the primary context for generating the response.\n",
    "If you don't know the answer or if the input data tables do not contain sufficient information to provide an answer, just say so. Do not make anything up.\n",
    "\n",
    "Each key point in the response should have the following element:\n",
    "- Description: A comprehensive description of the point.\n",
    "- Importance Score: An integer score between 0-100 that indicates how important the point is in answering the user's question. An 'I don't know' type of response should have a score of 0.\n",
    "\n",
    "The response shall preserve the original meaning and use of modal verbs such as \"shall\", \"may\" or \"will\".\n",
    "\n",
    "Points supported by data should list the relevant reports as references as follows:\n",
    "\"This is an example sentence supported by data references [Data: Reports (report ids)]\"\n",
    "\n",
    "**Do not list more than 5 record ids in a single reference**. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
    "\n",
    "For example:\n",
    "\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (2, 7, 64, 46, 34, +more)]. He is also CEO of company X [Data: Reports (1, 3)]\"\n",
    "\n",
    "where 1, 2, 3, 7, 34, 46, and 64 represent the id (not the index) of the relevant data report in the provided tables.\n",
    "\n",
    "Do not include information where the supporting evidence for it is not provided.\n",
    "\n",
    "The response should be JSON formatted as follows:\n",
    "{{\n",
    "    \"points\": [\n",
    "        {{\"description\": \"Description of point 1 [Data: Reports (report ids)]\", \"score\": score_value}},\n",
    "        {{\"description\": \"Description of point 2 [Data: Reports (report ids)]\", \"score\": score_value}}\n",
    "    ]\n",
    "}}\n",
    "\"\"\"\n",
    "map_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            MAP_SYSTEM_PROMPT,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"{question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "map_chain = map_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b5f3d00-fed8-4777-b3eb-8b990728d124",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "REDUCE_SYSTEM_PROMPT = \"\"\"\n",
    "---Role---\n",
    "\n",
    "You are a helpful assistant responding to questions about a dataset by synthesizing perspectives from multiple analysts.\n",
    "\n",
    "\n",
    "---Goal---\n",
    "\n",
    "Generate a response of the target length and format that responds to the user's question, summarize all the reports from multiple analysts who focused on different parts of the dataset.\n",
    "\n",
    "Note that the analysts' reports provided below are ranked in the **descending order of importance**.\n",
    "\n",
    "If you don't know the answer or if the provided reports do not contain sufficient information to provide an answer, just say so. Do not make anything up.\n",
    "\n",
    "The final response should remove all irrelevant information from the analysts' reports and merge the cleaned information into a comprehensive answer that provides explanations of all the key points and implications appropriate for the response length and format.\n",
    "\n",
    "Add sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\n",
    "\n",
    "The response shall preserve the original meaning and use of modal verbs such as \"shall\", \"may\" or \"will\".\n",
    "\n",
    "The response should also preserve all the data references previously included in the analysts' reports, but do not mention the roles of multiple analysts in the analysis process.\n",
    "\n",
    "**Do not list more than 5 record ids in a single reference**. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
    "\n",
    "For example:\n",
    "\n",
    "\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (2, 7, 34, 46, 64, +more)]. He is also CEO of company X [Data: Reports (1, 3)]\"\n",
    "\n",
    "where 1, 2, 3, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n",
    "\n",
    "Do not include information where the supporting evidence for it is not provided.\n",
    "\n",
    "\n",
    "---Target response length and format---\n",
    "\n",
    "{response_type}\n",
    "\n",
    "\n",
    "---Analyst Reports---\n",
    "\n",
    "{report_data}\n",
    "\n",
    "\n",
    "---Goal---\n",
    "\n",
    "Generate a response of the target length and format that responds to the user's question, summarize all the reports from multiple analysts who focused on different parts of the dataset.\n",
    "\n",
    "Note that the analysts' reports provided below are ranked in the **descending order of importance**.\n",
    "\n",
    "If you don't know the answer or if the provided reports do not contain sufficient information to provide an answer, just say so. Do not make anything up.\n",
    "\n",
    "The final response should remove all irrelevant information from the analysts' reports and merge the cleaned information into a comprehensive answer that provides explanations of all the key points and implications appropriate for the response length and format.\n",
    "\n",
    "The response shall preserve the original meaning and use of modal verbs such as \"shall\", \"may\" or \"will\".\n",
    "\n",
    "The response should also preserve all the data references previously included in the analysts' reports, but do not mention the roles of multiple analysts in the analysis process.\n",
    "\n",
    "**Do not list more than 5 record ids in a single reference**. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
    "\n",
    "For example:\n",
    "\n",
    "\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (2, 7, 34, 46, 64, +more)]. He is also CEO of company X [Data: Reports (1, 3)]\"\n",
    "\n",
    "where 1, 2, 3, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n",
    "\n",
    "Do not include information where the supporting evidence for it is not provided.\n",
    "\n",
    "\n",
    "---Target response length and format---\n",
    "\n",
    "{response_type}\n",
    "\n",
    "Add sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\n",
    "\"\"\"\n",
    "\n",
    "reduce_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            REDUCE_SYSTEM_PROMPT,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"{question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "reduce_chain = reduce_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ff40d87-240c-4512-95f6-0e442bd17a1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def global_retriever(query: str, level: int, response_type: str = \"multiple paragraphs\") -> str:\n",
    "    \"\"\"Global retriever\n",
    "\n",
    "    :param query: the question as string\n",
    "    :param level: the Community level\n",
    "    :param response_type: type of response\n",
    "    :returns: final response as a string\n",
    "    \"\"\"\n",
    "    community_query = f\"\"\"\n",
    "    PREFIX gr: <http://ormynet.com/ns/msft-graphrag#>\n",
    "    \n",
    "    SELECT ?full_content\n",
    "    WHERE {{\n",
    "        ?community_uri a gr:Community;\n",
    "        gr:level ?level;\n",
    "        gr:full_content ?full_content .\n",
    "        FILTER(?level = {level})\n",
    "    }}\n",
    "    \"\"\"\n",
    "    community_data = sparql_query(community_query)\n",
    "    intermediate_results = []\n",
    "    for i in tqdm(range(len(community_data)), desc=\"Processing communities\"):\n",
    "        intermediate_response = map_chain.invoke(\n",
    "            {\"question\": query, \"context_data\": community_data[\"full_content\"].iloc[i]}\n",
    "        )\n",
    "        intermediate_results.append(intermediate_response)\n",
    "    final_response = reduce_chain.invoke(\n",
    "        {\n",
    "            \"report_data\": intermediate_results,\n",
    "            \"question\": query,\n",
    "            \"response_type\": response_type,\n",
    "        }\n",
    "    )\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6df8353b-8fdb-4a99-8f15-8a696d58b92d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(global_retriever(\"What is the story about?\", 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "854472c6-398c-4098-9410-b8fa4f5a021a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_create_local_global",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
